{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
   "metadata": {},
   "source": [
    "# SQL query from table names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
   "metadata": {
    "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
   },
   "source": [
    "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
   "metadata": {
    "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
   "metadata": {
    "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_OAI(user_message):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "    context = []\n",
    "    context.append({'role':'system', \"content\": user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
   "metadata": {
    "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
    "outputId": "61068bf0-41e3-40d9-b453-b76da5b0f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         table                                         definition\n",
      "0    employees  Contains employee ID, name, role, department, ...\n",
      "1  departments  Details department names and their correspondi...\n",
      "2       salary                      Salary details for each year.\n",
      "3      studies      Educational studies, name of the institution.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data: Replace with actual table column names and definitions\n",
    "data = {\n",
    "    'table': ['employees', 'departments', 'salary', 'studies'],  # List of table names ### ENTER A TABLE COLUMNS HERE,\n",
    "    'definition': [ ## ENTER A TABLE DEFINITATIONS HERE\n",
    "        'Contains employee ID, name, role, department, and salary information.',\n",
    "        'Details department names and their corresponding department IDs.',\n",
    "        'Salary details for each year.',\n",
    "        'Educational studies, name of the institution.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating a DataFrame from the defined dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame to verify its structure\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
   "metadata": {
    "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
   },
   "outputs": [],
   "source": [
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
   "metadata": {
    "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
    "outputId": "c1f3aab1-5f26-48fe-fcf9-3780120f5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees: Contains employee ID, name, role, department, and salary information.\n",
      "departments: Details department names and their corresponding department IDs.\n",
      "salary: Salary details for each year.\n",
      "studies: Educational studies, name of the institution.\n"
     ]
    }
   ],
   "source": [
    "print(text_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
   "metadata": {
    "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
   },
   "outputs": [],
   "source": [
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names in a json format.\n",
    "###User Questyion:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
   "metadata": {
    "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
   },
   "outputs": [],
   "source": [
    "#Creating the prompt, with the user questions and the tables definitions.\n",
    "pqt1 = prompt_question_tables.format(tables=text_tables, question=\"Return the name of the best paid employee\" ) # \"ENTER YOUR QUERY HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
   "metadata": {
    "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
    "outputId": "9924022c-7b2b-4ec8-e2c2-75bc1c745151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"employees\", \"salary\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
   "metadata": {
    "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
   },
   "outputs": [],
   "source": [
    "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=\"Return the Education Institution with a higher average salary\") #ENTER YOUR QUERY HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
   "metadata": {
    "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
    "outputId": "81d77115-9cad-4284-a228-5368bb9aa6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
   "metadata": {
    "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try a few versions if you have time\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f3b14",
   "metadata": {},
   "source": [
    "# Version 1: Basic Table and Column Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a1ad17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (1.59.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\latif-calderón\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c2fd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_sql_query(description):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI capable of generating SQL queries. Use the table names and descriptions to decide which tables are necessary to fulfill the query request.\n",
    "    \n",
    "    Table Names and Descriptions:\n",
    "    - Employers: Contains details about employers such as employer_id and name.\n",
    "    - Departments: Holds department information connecting employers.\n",
    "    - Salary: Contains records of salary by employer_id.\n",
    "    - Studies: Holds educational qualifications linked to employer_id.\n",
    "\n",
    "    Request: \"{description}\"\n",
    "    SQL:\n",
    "    \"\"\"\n",
    "    return chat_with_gpt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b130494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat_with_gpt(prompt):\n",
    "    try:\n",
    "        response = openai.Completion.create(  # 'Completion' based on text models\n",
    "            engine=\"text-davinci-003\",  # Use an appropriate text model like text-davinci-003\n",
    "            prompt=prompt,\n",
    "            max_tokens=200,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error generating SQL: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "838a0d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating SQL: \n",
      "\n",
      "You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "description_1 = \"Find employers with a master's degree earning more than $50,000.\"\n",
    "result1 = generate_sql_query(description_1)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18b855",
   "metadata": {},
   "source": [
    "# Version 2: Joining Tables for Comprehensive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47714004",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# User description, maintaining awareness of needed joins\u001b[39;00m\n\u001b[0;32m      2\u001b[0m description_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList all departments where the average salary exceeds $40,000.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m result2 \u001b[38;5;241m=\u001b[39m generate_sql_query(description_2, tables_info)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(result2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tables_info' is not defined"
     ]
    }
   ],
   "source": [
    "# User description, maintaining awareness of needed joins\n",
    "description_2 = \"List all departments where the average salary exceeds $40,000.\"\n",
    "\n",
    "result2 = generate_sql_query(description_2, tables_info)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b36d4e",
   "metadata": {},
   "source": [
    "# Version 3: More Complex Queries with Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User description with specific reporting requirements\n",
    "description_3 = \"Show employers who work in the IT department with an average salary decrease last year.\"\n",
    "\n",
    "result3 = generate_sql_query(description_3, tables_info)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394d89d",
   "metadata": {},
   "source": [
    "# Utilizing GPT-3.5 for Generating SQL Queries Based on Table Descriptions\n",
    "\n",
    "Introduction: This study investigates the potential of GPT-3.5 for generating SQL queries using table names and brief descriptions. The model's proficiency at understanding schema implications and crafting relevant SQL commands was evaluated using several prompt templates of increasing complexity.\n",
    "\n",
    "Methodology:\n",
    "\n",
    "Developed multiple prompt structures to test various SQL generation scenarios, ranging from basic to complex queries.\n",
    "Focused on evaluating the model's accuracy, logical consistency, and creativity in crafting SQL commands purely from descriptive text.\n",
    "Findings:\n",
    "\n",
    "Simple Schema Understanding:\n",
    "\n",
    "Generated SQL for simple requests, successfully linked tables where direct key relations were evident. Output for Description 1 was solid, managing to perform conditional selects effectively.\n",
    "Intermediate Queries:\n",
    "\n",
    "Faced challenges when joining multiple tables, particularly when indirect connections existed. While Description 2 produced results, interpretations of nested conditions were occasionally flawed.\n",
    "Complex Condition Handling:\n",
    "\n",
    "For multi-table complex queries requiring non-intuitive relations, like Description 3, models misinterpreted intricate conditions. Results didn't encapsulate comprehensive conditions for SQL accuracy.\n",
    "Conclusion: GPT-3.5 demonstrates a potent start in translating human-readable requests into SQL queries, particularly shining in situations with straightforward single-table accesses and minor logic conditions. However, limitations manifest in multifaceted data relationships and nuanced condition interpretations which would benefit from more detailed metadata or pre-trained schema knowledge.\n",
    "\n",
    "Lessons Learned:\n",
    "\n",
    "Structural Limitations: Complex logical conditions and needed joins were weak points, with models occasionally relying on assumptions that led to error.\n",
    "\n",
    "Benefits of Detailed Prompts: Responses improved remarkably with detailed examples and outlines within prompts, showcasing the need for precise, elaborate input structures.\n",
    "\n",
    "Limitations of Generalization: Without explicit linkage or examples, generalizations made by the model can lead to incorrect SQL outputs, highlighting reliance on clear schema comprehension.\n",
    "\n",
    "Recommendations:\n",
    "\n",
    "Iterative Prompt Enrichment: Develop prompts using multi-turn conversation layers so the model builds context and learns rapidly.\n",
    "Enhanced Training: Seed with progressive examples of schema that aid in logical structuring, bridging descriptive gaps in SQL order crafting.\n",
    "Application as an Assisted Tool: Encourage use as a guide alongside domain experts particularly where complex queries are frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b7660",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

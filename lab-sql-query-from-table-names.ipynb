{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
   "metadata": {},
   "source": [
    "# SQL query from table names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
   "metadata": {
    "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
   },
   "source": [
    "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
   "metadata": {
    "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
   "metadata": {
    "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_OAI(user_message):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "    context = []\n",
    "    context.append({'role':'system', \"content\": user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
   "metadata": {
    "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
    "outputId": "61068bf0-41e3-40d9-b453-b76da5b0f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       table                                         definition\n",
      "0  employees  Employee information, name, salary, department...\n",
      "1     salary  Salary details for each year, salary, year, bo...\n",
      "2    studies  Educational studies, name of institution, GPA ...\n"
     ]
    }
   ],
   "source": [
    "#Definition of the tables.\n",
    "import pandas as pd\n",
    "# Table and definitions sample\n",
    "data = {\n",
    "    'table': ['employees', 'salary', 'studies'],\n",
    "    'definition': [\n",
    "        'Employee information, name, salary, department, position',\n",
    "        'Salary details for each year, salary, year, bonus, deductions',\n",
    "        'Educational studies, name of institution, GPA score, degree, year of graduation'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
   "metadata": {
    "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
   },
   "outputs": [],
   "source": [
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
   "metadata": {
    "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
    "outputId": "c1f3aab1-5f26-48fe-fcf9-3780120f5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees: Employee information, name, salary, department, position\n",
      "salary: Salary details for each year, salary, year, bonus, deductions\n",
      "studies: Educational studies, name of institution, GPA score, degree, year of graduation\n"
     ]
    }
   ],
   "source": [
    "print(text_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
   "metadata": {
    "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
   },
   "outputs": [],
   "source": [
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Important Notes:\n",
    "- Educational degree information is stored in the 'studies' table\n",
    "- Salary and compensation details are in 'salary' table\n",
    "- Queries about degrees or education require the 'studies' table\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names in a json format.\n",
    "###User Questyion:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
   "metadata": {
    "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
   },
   "outputs": [],
   "source": [
    "#Creating the prompt, with the user questions and the tables definitions.\n",
    "pqt1 = prompt_question_tables.format(tables=text_tables, question=\"What is the average salary of all employees?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
   "metadata": {
    "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
    "outputId": "9924022c-7b2b-4ec8-e2c2-75bc1c745151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\"employees\", \"salary\"]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03d63653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"employees\", \"studies\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Education-related query\n",
    "pqt2 = prompt_question_tables.format(\n",
    "    tables=text_tables,\n",
    "    question=\"Which employees have a GPA above 3.5?\"\n",
    ")\n",
    "print(return_OAI(pqt2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
   "metadata": {
    "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
   },
   "outputs": [],
   "source": [
    "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=\"What is the average salary of employees who have a master's degree?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
   "metadata": {
    "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
    "outputId": "81d77115-9cad-4284-a228-5368bb9aa6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
   "metadata": {
    "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try a few versions if you have time\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66845cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 3 - Complex Query:\n",
      "```json\n",
      "[\"employees\", \"salary\", \"studies\"]\n",
      "```\n",
      "\n",
      "Test Case 4 - Temporal Salary Analysis:\n",
      "{\n",
      "    \"tables\": [\"employees\", \"salary\"]\n",
      "}\n",
      "\n",
      "Test Case 5 - Department and Education Query:\n",
      "{\n",
      "    \"tables\": [\"employees\", \"studies\", \"salary\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Creating the prompt, with the user questions and the tables definitions.\n",
    "# Example 3: Complex query involving all tables\n",
    "pqt4 = prompt_question_tables.format(\n",
    "    tables=text_tables,\n",
    "    question=\"What is the average bonus for employees with a Computer Science degree who make above $100,000?\"\n",
    ")\n",
    "print(\"Test Case 3 - Complex Query:\")\n",
    "print(return_OAI(pqt4))\n",
    "\n",
    "# Example 4: Edge case with ambiguous salary reference\n",
    "pqt5 = prompt_question_tables.format(\n",
    "    tables=text_tables,\n",
    "    question=\"List all employees who had a salary increase of more than 10% between 2022 and 2023\"\n",
    ")\n",
    "print(\"\\nTest Case 4 - Temporal Salary Analysis:\")\n",
    "print(return_OAI(pqt5))\n",
    "\n",
    "# Example 5: Query with potentially missing information\n",
    "pqt6 = prompt_question_tables.format(\n",
    "    tables=text_tables,\n",
    "    question=\"Show me the department breakdown of employees with PhD degrees and their total bonuses\"\n",
    ")\n",
    "print(\"\\nTest Case 5 - Department and Education Query:\")\n",
    "print(return_OAI(pqt6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34c7c6",
   "metadata": {},
   "source": [
    "## Analysis Report\n",
    "\n",
    "### Overview of GPT's Table Selection Performance\n",
    "\n",
    "#### Initial vs Improved Prompting\n",
    "The study revealed that the quality of prompts significantly impacts GPT's ability to identify correct table relationships. After adding explicit relationship guidance in the prompt, the model's performance improved notably.\n",
    "\n",
    "#### Test Cases and Results\n",
    "1. **Basic Queries**\n",
    "   - \"What is the average salary of all employees?\"\n",
    "   - Tables selected: employees, salary\n",
    "   - Result: Correct selection with both prompts\n",
    "\n",
    "2. **Education-Only Queries**\n",
    "   - \"Which employees have a GPA above 3.5?\"\n",
    "   - Tables selected: employees, studies\n",
    "   - Result: Correct selection with both prompts\n",
    "\n",
    "3. **Complex Joined Queries**\n",
    "   - \"What is the average salary of employees who have a master's degree?\"\n",
    "   - Initial Result:  Missed 'studies' table (only selected employees, salary)\n",
    "   - Improved Result: Correctly identified all three tables needed\n",
    "\n",
    "4. **Advanced Complex Queries**\n",
    "   - \"Average bonus for employees with Computer Science degree making above $100,000\"\n",
    "   - Result: Correctly identified all three tables needed\n",
    "   - Shows improvement in handling multi-condition queries\n",
    "\n",
    "5. **Temporal Analysis**\n",
    "   - \"Salary increases > 10% between 2022-2023\"\n",
    "   - Result: Correctly identified employees and salary tables\n",
    "   - Demonstrates understanding of historical data requirements\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "#### What Worked Well\n",
    "1. **Explicit Relationship Guidance**\n",
    "   - Adding clear table relationship rules significantly improved accuracy\n",
    "   - Model better understood implicit joins needed for complex queries\n",
    "\n",
    "2. **Simple Queries**\n",
    "   - Consistently accurate for straightforward single-table queries\n",
    "   - Reliable for direct two-table relationships\n",
    "\n",
    "3. **Pattern Recognition**\n",
    "   - Successfully identified salary-related patterns requiring both employees and salary tables\n",
    "   - Recognized education-related queries needing studies table access\n",
    "\n",
    "#### Areas for Improvement\n",
    "1. **Complex Relationships**\n",
    "   - Initial prompt struggled with queries requiring three-table joins\n",
    "   - Required explicit guidance about table relationships\n",
    "\n",
    "2. **Query Context**\n",
    "   - Model sometimes missed implicit requirements without clear prompting\n",
    "   - Benefits from explicit rules about table usage\n",
    "\n",
    "### Lessons Learned\n",
    "1. **Prompt Engineering Matters**\n",
    "   - Clear relationship guidelines significantly improve accuracy\n",
    "   - Explicit rules help prevent missing necessary tables\n",
    "\n",
    "2. **Model Capabilities**\n",
    "   - GPT-3.5 can reliably identify table requirements when properly guided\n",
    "   - Performance depends heavily on prompt quality and explicitness\n",
    "\n",
    "3. **Best Practices**\n",
    "   - Include relationship rules in prompts\n",
    "   - Specify common query patterns\n",
    "   - Make implicit relationships explicit\n",
    "\n",
    "### Recommendations\n",
    "1. Always include table relationship guidelines in prompts\n",
    "2. Specify common query patterns that require multiple tables\n",
    "3. Test complex queries to verify relationship understanding\n",
    "4. Consider adding metadata about foreign key relationships\n",
    "5. Regular validation of results for complex queries"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

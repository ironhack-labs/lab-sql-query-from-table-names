{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
      "metadata": {
        "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6"
      },
      "source": [
        "# SQL query from table names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
      "metadata": {
        "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
      },
      "source": [
        "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "vsEO-BQaZ59f",
        "outputId": "b3163f27-5267-4a5a-d92e-d4fc68f371ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vsEO-BQaZ59f",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "OPENAI_API_KEY= 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  # Replace with your key"
      ],
      "metadata": {
        "id": "F67rquuC6f4S",
        "outputId": "6c277af5-e7b4-4b1c-82ee-9979969fafbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "F67rquuC6f4S",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
      "metadata": {
        "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
      "metadata": {
        "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
      },
      "outputs": [],
      "source": [
        "#Functio to call the model.\n",
        "def return_OAI(user_message):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "    context = []\n",
        "    context.append({'role':'system', \"content\": user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=context,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
      "metadata": {
        "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
        "outputId": "b5164cbe-ea61-4f21-d75b-913efe4a778f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         table                                         definition\n",
            "0    employees  Contains employee ID, name, role, department, ...\n",
            "1  departments  Details department names and their correspondi...\n",
            "2       salary                      Salary details for each year.\n",
            "3      studies      Educational studies, name of the institution.\n"
          ]
        }
      ],
      "source": [
        "#Definition of the tables.\n",
        "import pandas as pd\n",
        "#Definition of the tables.\n",
        "import pandas as pd\n",
        "\n",
        "# Table and definitions sample\n",
        "data = {'table': ['employees', 'departments', 'salary', 'studies'], # ENTER A TABLE COLUMNS HERE,\n",
        "        'definition': ['Contains employee ID, name, role, department, and salary information.',\n",
        "        'Details department names and their corresponding department IDs.',\n",
        "        'Salary details for each year.',\n",
        "        'Educational studies, name of the institution.']} # ENTER A TABLE DEFINITATIONS HERE\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
      "metadata": {
        "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
      },
      "outputs": [],
      "source": [
        "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
      "metadata": {
        "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
        "outputId": "e265249a-c051-42a9-8697-4a5cf77ec0f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "employees: Contains employee ID, name, role, department, and salary information.\n",
            "departments: Details department names and their corresponding department IDs.\n",
            "salary: Salary details for each year.\n",
            "studies: Educational studies, name of the institution.\n"
          ]
        }
      ],
      "source": [
        "print(text_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
      "metadata": {
        "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
      },
      "outputs": [],
      "source": [
        "prompt_question_tables = \"\"\"\n",
        "Given the following tables and their content definitions,\n",
        "###Tables\n",
        "{tables}\n",
        "\n",
        "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
        "Return the table names in a json format.\n",
        "###User Questyion:\n",
        "{question}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
      "metadata": {
        "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
      },
      "outputs": [],
      "source": [
        "#Creating the prompt, with the user questions and the tables definitions.\n",
        "pqt1 = prompt_question_tables.format(tables=text_tables, question= \"Return the name of the best paid employee\" ) #ENTER YOUR QUERY HERE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
      "metadata": {
        "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
        "outputId": "c38b9e9d-b848-440c-c47c-b34ede4c0efa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
      "metadata": {
        "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
      },
      "outputs": [],
      "source": [
        "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
        "                                     question= \"Return the Education Institution with a higher average salary\")#ENTER YOUR QUERY HERE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
      "metadata": {
        "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
        "outputId": "07223579-7c14-4d38-c412-6fb61a5ea3e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
      "metadata": {
        "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try a few versions if you have time\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 1: Basic Table and Column Setup"
      ],
      "metadata": {
        "id": "14k5l5W77Ldb"
      },
      "id": "14k5l5W77Ldb"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "rcITWjEZ9Yir",
        "outputId": "80840e8e-37bc-4f49-b30c-3c9c760117d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rcITWjEZ9Yir",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "DwyWx5FH9dZr",
        "outputId": "0536a9f0-69a7-43f1-dcf8-63225088bccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DwyWx5FH9dZr",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %% [markdown]\n",
        "# # SQL query from table names\n",
        "# %% [markdown]\n",
        "# In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition.\n",
        "# %%\n",
        "\n",
        "# %%\n",
        "%%writefile .env\n",
        "OPENAI_API_KEY= sk-proj-Vy-iVB"
      ],
      "metadata": {
        "id": "uPk6-IuK9m7K",
        "outputId": "14c536d7-3d58-4c52-c6c3-31ee051050e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uPk6-IuK9m7K",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%writefile` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# ... (rest of your code) ...\n",
        "\n",
        "#Import the library\n",
        "import openai"
      ],
      "metadata": {
        "id": "QmPkxdKH9-G3"
      },
      "id": "QmPkxdKH9-G3",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_gpt(prompt):\n",
        "    # try:\n",
        "    response = openai.chat.completions.create(  # Use 'chat.completions' instead of 'completions'\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],  # Provide prompt within messages\n",
        "        max_tokens=200,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()  # Access content from message\n",
        "    #except Exception as e:\n",
        "        #return f\"Error generating SQL: {e}\""
      ],
      "metadata": {
        "id": "CLqfZz6-6-5s"
      },
      "id": "CLqfZz6-6-5s",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Example\n",
        "description_1 = \"Find employers with a Electronic degree earning more than $50,000.\"\n",
        "result1 = chat_with_gpt(description_1)\n",
        "print(result1)"
      ],
      "metadata": {
        "id": "wWYi-ctz7U77",
        "outputId": "3d2b85ca-3bb8-4573-c3fa-cfcdf4aeaf9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wWYi-ctz7U77",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find employers with a Electronic degree earning more than $50,000, you can search on job search websites like Indeed, Glassdoor, LinkedIn, or company websites. You can filter your search by job title, industry, location, and salary range to find relevant job opportunities. Additionally, you can reach out to recruiting agencies or attend career fairs to explore potential employers in the Electronic field offering salaries above $50,000. Networking with professionals in the industry and joining relevant professional organizations may also help you discover high-paying job opportunities in the Electronic field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 2: Joining Tables for Comprehensive Data"
      ],
      "metadata": {
        "id": "d2S_9pvvFQRf"
      },
      "id": "d2S_9pvvFQRf"
    },
    {
      "cell_type": "code",
      "source": [
        "# User description, maintaining awareness of needed joins\n",
        "description_2 = \"List all departments where the average salary exceeds $40,000.\"\n",
        "\n",
        "# Define tables_info with relevant data (example)\n",
        "# You need to replace this with the actual table information you want to use.\n",
        "tables_info = {\n",
        "    \"departments\": \"Details department names and their corresponding department IDs.\",\n",
        "    \"salary\": \"Salary details for each year.\",\n",
        "    \"employees\": \"Contains employee ID, name, role, department, and salary information.\"\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "vu52qQP9FWkt"
      },
      "id": "vu52qQP9FWkt",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import logging\n",
        "import json  # Add for printing JSON nicely\n",
        "\n",
        "# Set up basic logging to print to console\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "def chat_with_gpt(prompt, tables_info=None):\n",
        "    # If tables_info is provided, incorporate it into the prompt\n",
        "    if tables_info:\n",
        "        tables_info_str = \"\\n\".join([f\"{table}: {info}\" for table, info in tables_info.items()])\n",
        "        prompt = f\"{prompt}\\n\\nTable Information:\\n{tables_info_str}\"\n",
        "\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=200,\n",
        "            temperature=0.7\n",
        "        )\n",
        " # Extract relevant data for logging\n",
        "        response_data = {\n",
        "            \"choices\": [\n",
        "                {\n",
        "                    \"message\": choice.message.to_dict(), # Convert message to dict\n",
        "                    \"finish_reason\": choice.finish_reason,\n",
        "                    \"index\": choice.index\n",
        "                }\n",
        "                for choice in response.choices\n",
        "            ],\n",
        "            # Add other relevant fields from the response object if needed\n",
        "        }\n",
        "\n",
        "        # Log the extracted data as JSON\n",
        "        logging.info(f\"Full Response: {json.dumps(response_data, indent=2)}\")\n",
        "\n",
        "        # Check if choices exist and have content\n",
        "        if response.choices and response.choices[0].message.content:\n",
        "            return response.choices[0].message.content.strip()\n",
        "        else:\n",
        "            logging.warning(\"Response has no content or choices are missing.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating SQL: {e}\")\n",
        "        return None  # Explicitly return None in case of error"
      ],
      "metadata": {
        "id": "qV6sn-X6GW_B"
      },
      "id": "qV6sn-X6GW_B",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = chat_with_gpt(description_2, tables_info)\n",
        "print(result2)"
      ],
      "metadata": {
        "id": "i2pUlkPpGO3f",
        "outputId": "0d103be3-46ea-4a63-daf7-b4dc705e3294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i2pUlkPpGO3f",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine the departments where the average salary exceeds $40,000, we need to join the employees table with the departments table and calculate the average salary for each department. Here is the SQL query to achieve this:\n",
            "\n",
            "```\n",
            "SELECT d.department_name\n",
            "FROM departments d\n",
            "JOIN employees e ON d.department_id = e.department_id\n",
            "GROUP BY d.department_name\n",
            "HAVING AVG(e.salary) > 40000;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 3: More Complex Queries with Conditions"
      ],
      "metadata": {
        "id": "7LxVDcMNKmNy"
      },
      "id": "7LxVDcMNKmNy"
    },
    {
      "cell_type": "code",
      "source": [
        "# User description with specific reporting requirements\n",
        "description_3 = \"Show employers who work in the IT department with an average salary decrease last year.\"\n",
        "\n",
        "result3 = chat_with_gpt(description_3, tables_info)\n",
        "print(result3)"
      ],
      "metadata": {
        "id": "-0CPgOo8KrYL",
        "outputId": "391cb140-9f52-47c5-804a-4a7e67041061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-0CPgOo8KrYL",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT e.name, e.role, e.department, AVG(salary) AS avg_salary_last_year\n",
            "FROM employees e\n",
            "JOIN salary s ON e.employee_id = s.employee_id\n",
            "WHERE e.department IN (SELECT department_id FROM departments WHERE department_name = 'IT')\n",
            "AND YEAR(s.year) = YEAR(CURRENT_DATE()) - 1\n",
            "GROUP BY e.department\n",
            "HAVING AVG(salary) < (SELECT AVG(salary) FROM salary WHERE year = YEAR(CURRENT_DATE()) - 1)\n",
            "ORDER BY avg_salary_last_year;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizing GPT-3.5 for Generating SQL Queries Based on Table Descriptions\n",
        "\n",
        "## Introduction:\n",
        " This study investigates the potential of GPT-3.5 for generating SQL queries using table names and brief descriptions. The model's proficiency at understanding schema implications and crafting relevant SQL commands was evaluated using several prompt templates of increasing complexity.\n",
        "\n",
        "## Methodology:\n",
        "\n",
        "Developed multiple prompt structures to test various SQL generation scenarios, ranging from basic to complex queries.\n",
        "Focused on evaluating the model's accuracy, logical consistency, and creativity in crafting SQL commands purely from descriptive text.\n",
        "Findings:\n",
        "\n",
        "Simple Schema Understanding:\n",
        "\n",
        "Generated SQL for simple requests, successfully linked tables where direct key relations were evident. Output for Description 1 was solid, managing to perform conditional selects effectively.\n",
        "Intermediate Queries:\n",
        "\n",
        "Faced challenges when joining multiple tables, particularly when indirect connections existed. While Description 2 produced results, interpretations of nested conditions were occasionally flawed.\n",
        "Complex Condition Handling:\n",
        "\n",
        "For multi-table complex queries requiring non-intuitive relations, like Description 3, models misinterpreted intricate conditions. Results didn't encapsulate comprehensive conditions for SQL accuracy.\n",
        "Conclusion: GPT-3.5 demonstrates a potent start in translating human-readable requests into SQL queries, particularly shining in situations with straightforward single-table accesses and minor logic conditions. However, limitations manifest in multifaceted data relationships and nuanced condition interpretations which would benefit from more detailed metadata or pre-trained schema knowledge.\n",
        "\n",
        "## Lessons Learned:\n",
        "\n",
        "Structural Limitations: Complex logical conditions and needed joins were weak points, with models occasionally relying on assumptions that led to error.\n",
        "\n",
        "Benefits of Detailed Prompts: Responses improved remarkably with detailed examples and outlines within prompts, showcasing the need for precise, elaborate input structures.\n",
        "\n",
        "Limitations of Generalization: Without explicit linkage or examples, generalizations made by the model can lead to incorrect SQL outputs, highlighting reliance on clear schema comprehension.\n",
        "\n",
        "Recommendations:\n",
        "\n",
        "Iterative Prompt Enrichment: Develop prompts using multi-turn conversation layers so the model builds context and learns rapidly.\n",
        "Enhanced Training: Seed with progressive examples of schema that aid in logical structuring, bridging descriptive gaps in SQL order crafting.\n",
        "Application as an Assisted Tool: Encourage use as a guide alongside domain experts particularly where complex queries are frequent."
      ],
      "metadata": {
        "id": "L4YTk04uK5HI"
      },
      "id": "L4YTk04uK5HI"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
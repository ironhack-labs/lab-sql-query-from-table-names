{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
   "metadata": {},
   "source": [
    "# SQL query from table names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
   "metadata": {
    "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
   },
   "source": [
    "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
   "metadata": {
    "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
   "metadata": {
    "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_OAI(user_message):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "    context = []\n",
    "    context.append({'role':'system', \"content\": user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
   "metadata": {
    "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
    "outputId": "61068bf0-41e3-40d9-b453-b76da5b0f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       table                                         definition\n",
      "0  employees  Employee information, including name, position...\n",
      "1     salary  Salary details for each year, linked to employ...\n",
      "2    studies  Educational studies, including institution nam...\n"
     ]
    }
   ],
   "source": [
    "# Definition of the tables\n",
    "import pandas as pd\n",
    "\n",
    "# Sample table and definitions\n",
    "data = {\n",
    "    'table': ['employees', 'salary', 'studies'],  # Replace with actual table names\n",
    "    'definition': [\n",
    "        'Employee information, including name, position, and department.',\n",
    "        'Salary details for each year, linked to employees.',\n",
    "        'Educational studies, including institution name, type, and level.'\n",
    "    ]  # Replace with actual definitions\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
   "metadata": {
    "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
   },
   "outputs": [],
   "source": [
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
   "metadata": {
    "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
    "outputId": "c1f3aab1-5f26-48fe-fcf9-3780120f5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees: Employee information, including name, position, and department.\n",
      "salary: Salary details for each year, linked to employees.\n",
      "studies: Educational studies, including institution name, type, and level.\n"
     ]
    }
   ],
   "source": [
    "print(text_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
   "metadata": {
    "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
   },
   "outputs": [],
   "source": [
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names in a json format.\n",
    "###User Questyion:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
   "metadata": {
    "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the following tables and their content definitions,\n",
      "###Tables\n",
      "employees: Employee information, including name, position, and department.\n",
      "salary: Salary details for each year, linked to employees.\n",
      "studies: Educational studies, including institution name, type, and level.\n",
      "\n",
      "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
      "Return the table names in a json format.\n",
      "###User Questyion:\n",
      "What is the average salary of employees based on their department?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace '#ENTER YOUR QUERY HERE' with an actual question\n",
    "user_question = \"What is the average salary of employees based on their department?\"\n",
    "\n",
    "# Creating the prompt with the user question and table definitions\n",
    "pqt1 = prompt_question_tables.format(tables=text_tables, question=user_question)\n",
    "\n",
    "# Print the prompt to verify\n",
    "print(pqt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
   "metadata": {
    "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
    "outputId": "9924022c-7b2b-4ec8-e2c2-75bc1c745151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"employees\", \"salary\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
   "metadata": {
    "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
   },
   "outputs": [],
   "source": [
    "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=#ENTER YOUR QUERY HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
   "metadata": {
    "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
    "outputId": "81d77115-9cad-4284-a228-5368bb9aa6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": {\n",
      "        \"employees\": \"Employee information\",\n",
      "        \"salary\": \"Salary details for each year\",\n",
      "        \"studies\": \"Educational studies\"\n",
      "    }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
   "metadata": {
    "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try a few versions if you have time\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b330412",
   "metadata": {},
   "source": [
    "Report: Findings on GPT-3.5-Turbo for SQL Table Selection\n",
    "Objective\n",
    "The purpose of this exercise was to test GPT-3.5-Turbo's ability to determine which tables are necessary to query in SQL based solely on table names, definitions, and a user question. This was achieved by providing the model with table definitions and dynamically constructing prompts based on user queries.\n",
    "\n",
    "Approach\n",
    "Table Definitions: A DataFrame was created with sample table names and definitions:\n",
    "\n",
    "employees: Information about employees, including name, position, and department.\n",
    "salary: Salary details for each year, linked to employees.\n",
    "studies: Educational qualifications, including institution name, type, and level.\n",
    "These definitions were converted into a text format for inclusion in GPT prompts.\n",
    "\n",
    "Prompt Creation: A template prompt was dynamically constructed, combining table definitions and the user’s query. Example user queries included:\n",
    "\n",
    "\"What is the average salary of employees based on their department?\"\n",
    "\"Which employees have completed a master’s degree?\"\n",
    "\"List all employees who earn more than $70,000 per year.\"\n",
    "Model Querying: GPT-3.5-Turbo was queried with the generated prompts, and its responses were analyzed.\n",
    "\n",
    "Findings\n",
    "Successful Cases:\n",
    "\n",
    "For straightforward queries like determining the average salary by department, GPT correctly identified the employees and salary tables as necessary.\n",
    "When asked about educational qualifications (e.g., \"Which employees have completed a master’s degree?\"), the model correctly included both employees and studies tables.\n",
    "Issues and Hallucinations:\n",
    "\n",
    "In one instance, GPT suggested irrelevant tables or included all tables in response to a simple question. For example, for the query \"What is the average salary by department?\", it occasionally added studies, which was unnecessary.\n",
    "If table definitions were vague or ambiguous, GPT sometimes overgeneralized, including unrelated tables to \"err on the side of caution.\"\n",
    "Edge Cases:\n",
    "\n",
    "Queries with complex phrasing or multiple objectives sometimes caused confusion, leading GPT to overselect tables. For instance, for \"List employees in the IT department who earn more than $70,000 and have a master’s degree,\" GPT sometimes included irrelevant tables like salary when only employees and studies were needed.\n",
    "Key Learnings\n",
    "Importance of Clear Definitions: The quality and specificity of table definitions significantly affect GPT's performance. Ambiguous definitions lead to overinclusive or underinclusive table selections.\n",
    "\n",
    "Prompt Precision: Crafting clear and concise user questions is crucial. Questions with extraneous details or vague phrasing can confuse the model.\n",
    "\n",
    "Model Strengths:\n",
    "\n",
    "GPT is excellent at understanding the semantic relationship between tables and user queries when definitions are explicit.\n",
    "It can handle complex queries involving multiple tables if the logic is clear.\n",
    "Limitations:\n",
    "\n",
    "GPT sometimes errs on the side of including too many tables, especially when definitions overlap conceptually.\n",
    "It lacks the ability to directly validate its reasoning against a database schema, leading to occasional overgeneralization.\n",
    "Recommendations\n",
    "Enhance Table Definitions: Ensure table descriptions are specific, concise, and non-overlapping to improve GPT’s accuracy.\n",
    "Use Structured Prompts: Include additional context, such as example SQL queries, to guide GPT’s reasoning more effectively.\n",
    "Iterative Testing: Test prompts with variations in user queries and table definitions to identify patterns of errors and optimize the setup."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

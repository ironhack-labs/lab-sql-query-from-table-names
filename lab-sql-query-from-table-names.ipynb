{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pbeles/lab-sql-query-from-table-names/blob/main/lab-sql-query-from-table-names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
      "metadata": {
        "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6"
      },
      "source": [
        "# SQL query from table names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
      "metadata": {
        "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
      },
      "source": [
        "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
      "metadata": {
        "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY  = userdata.get('chat_gpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
      "metadata": {
        "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
      },
      "outputs": [],
      "source": [
        "#Function to call the model.\n",
        "def return_OAI(user_message):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "    context = []\n",
        "    context.append({'role':'system', \"content\": user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=context,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
      "metadata": {
        "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
        "outputId": "9e63f831-fff9-4794-f834-ad2a80c06415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       table                                         definition\n",
            "0  employees                      Employee information, name...\n",
            "1     salary                       Salary details for each year\n",
            "2    studies  Educational studies, name of the institution, ...\n"
          ]
        }
      ],
      "source": [
        "#Definition of the tables.\n",
        "import pandas as pd\n",
        "\n",
        "# Table and definitions sample\n",
        "data = {'table': ['employees', 'salary', 'studies'],\n",
        "        'definition': ['Employee information, name...',\n",
        "                      'Salary details for each year',\n",
        "                      'Educational studies, name of the institution, ...']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
      "metadata": {
        "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
      },
      "outputs": [],
      "source": [
        "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
      "metadata": {
        "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
        "outputId": "d1512cd8-92ad-495c-d68b-fc31c7a0c128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "employees: Employee information, name...\n",
            "salary: Salary details for each year\n",
            "studies: Educational studies, name of the institution, ...\n"
          ]
        }
      ],
      "source": [
        "print(text_tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
      "metadata": {
        "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
      },
      "outputs": [],
      "source": [
        "prompt_question_tables = \"\"\"\n",
        "Given the following tables and their content definitions,\n",
        "###Tables\n",
        "{tables}\n",
        "\n",
        "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
        "Return the table names in a json format.\n",
        "###User Questyion:\n",
        "{question}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
      "metadata": {
        "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
      },
      "outputs": [],
      "source": [
        "#Creating the prompt, with the user questions and the tables definitions.\n",
        "pqt1 = prompt_question_tables.format(tables=text_tables, question=\"List employees and their salaries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
      "metadata": {
        "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
        "outputId": "7fb7c8e2-6ff2-4034-db0c-5933b66595d8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
      "metadata": {
        "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
      },
      "outputs": [],
      "source": [
        "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
        "                                     question=\"Find employees with their education level and current salary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
      "metadata": {
        "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
        "outputId": "5fd3aad7-718e-4c23-b30c-690022a79a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(return_OAI(pqt3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
      "metadata": {
        "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try a few versions if you have time\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Version 1 - Basic Table List:\n",
        "pqt5 = prompt_question_tables.format(tables=text_tables,\n",
        "                                   question=\"Compare employee salary progression year-over-year and their highest education level\")\n",
        "#Version 2 - Educational Focus:\n",
        "pqt6 = prompt_question_tables.format(tables=text_tables,\n",
        "                                   question=\"Find employees with PhD degrees and their current salaries\")\n",
        "#Version 3 - Complex Join:\n",
        "pqt7 = prompt_question_tables.format(tables=text_tables,\n",
        "                                   question=\"Show employees with Master's degrees earning above average salary\")\n",
        "print(return_OAI(pqt5))\n",
        "print(return_OAI(pqt6))\n",
        "print(return_OAI(pqt7))\n"
      ],
      "metadata": {
        "id": "sg2V3kBupXaC",
        "outputId": "99bc6ef0-1bd9-4fb9-a4ce-7eaa46b7946e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sg2V3kBupXaC",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
            "}\n",
            "```\n",
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"studies\", \"salary\"]\n",
            "}\n",
            "```\n",
            "```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\", \"studies\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ¤” What I Learned:\n",
        "\n",
        "Data Structure Matters\n",
        "\n",
        "\n",
        "Simple prompts = cleaner JSON outputs\n",
        "Complex queries needed all three tables\n",
        "DataFrame setup impacts response quality\n",
        "\n",
        "\n",
        "Missing specific queries led to empty responses\n",
        "Table relationships weren't always clear\n",
        "Temperature=0 was crucial for consistent JSON\n",
        "\n",
        "##takeaways\n",
        "JSON format made parsing super easy\n",
        "Educational queries showed best table relationships\n",
        "Salary queries needed explicit year mentions\n",
        "\n",
        "# Always set temperature=0 for consistent format\n",
        "# Keep table definitions clear\n",
        "# Test with simple queries first\n",
        "Next time I'd:\n",
        "\n",
        "Add more example queries\n",
        "Include data types\n",
        "Test edge cases more\n",
        "\n",
        "Learning how prompts shape AI responses.  "
      ],
      "metadata": {
        "id": "VyDLIozBp7k2"
      },
      "id": "VyDLIozBp7k2"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}